{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6IFVX1Ul9q02dUAZDRzXe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexanderLontke/ssl-remote-sensing/blob/main/notebooks/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN Implementation Remote Sensing"
      ],
      "metadata": {
        "id": "OUFTlSkiXFbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import necessary packages"
      ],
      "metadata": {
        "id": "UZR3Bk_fXN6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaLT1SVkRd8F",
        "outputId": "6d0b0a1c-4c29-49da-d9d9-eb2e5a8b051c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 503 kB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from rasterio) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio) (22.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio) (2022.9.24)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rasterio) (1.21.6)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio) (57.4.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.2.10 snuggs-1.4.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.10-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 69.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 859 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.9.24)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.9.9-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[K     |████████████████████████████████| 162 kB 65.1 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.8-py2.py3-none-any.whl (158 kB)\n",
            "\u001b[K     |████████████████████████████████| 158 kB 63.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.7-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 70.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.6-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 69.5 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.5-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 71.2 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.4-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 67.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.3-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.4 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.2-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 61.6 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.1-py2.py3-none-any.whl (157 kB)\n",
            "\u001b[K     |████████████████████████████████| 157 kB 58.8 MB/s \n",
            "\u001b[?25h  Downloading sentry_sdk-1.9.0-py2.py3-none-any.whl (156 kB)\n",
            "\u001b[K     |████████████████████████████████| 156 kB 67.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9b2a705035602b3912fe81883da6d5957b79987b9334001c3d219ded9e024ed9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.29 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.9.0 setproctitle-1.3.2 shortuuid-1.0.9 smmap-5.0.0 wandb-0.13.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Hz_3erdBWzaw"
      },
      "outputs": [],
      "source": [
        "# import standard python libraries\n",
        "import os\n",
        "import datetime as time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import glob\n",
        "from pathlib import Path\n",
        "from math import floor\n",
        "import random\n",
        "\n",
        "# import data reader, logging and transforms\n",
        "from torchvision import transforms\n",
        "import rasterio as rio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import wandb\n",
        "\n",
        "# import the PyTorch deep learning library\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# import matplotlib and enabling notebook inline plotting:\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive Directories for data access"
      ],
      "metadata": {
        "id": "LLeVdwxiRP9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the Google Colab GDrive connector\n",
        "from google.colab import drive\n",
        "\n",
        "# mount GDrive inside the Colab notebook\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSIjW4MYRQIb",
        "outputId": "a4b6112c-b4fb-474b-8773-c587505378a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create Colab Notebooks directory\n",
        "notebook_directory = Path('/content/drive/MyDrive/Projects/DeepLearning')\n",
        "if not os.path.exists(notebook_directory): os.makedirs(notebook_directory)\n",
        "\n",
        " # create data sub-directory inside the Colab Notebooks directory\n",
        "data_directory = Path('/content/drive/MyDrive/Projects/DeepLearning/data')\n",
        "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
        "\n",
        " # create models sub-directory inside the Colab Notebooks directory\n",
        "models_directory = Path('/content/drive/MyDrive/Projects/DeepLearning/models')\n",
        "if not os.path.exists(models_directory): os.makedirs(models_directory)"
      ],
      "metadata": {
        "id": "S65evWlYSgdL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "xONKWBsXQuc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eADzr_OdYuxV",
        "outputId": "2a071751-e58f-430d-8997-35a736298817"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] notebook with cuda computation enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(SEED)\n",
        "if device == \"cuda\":\n",
        "  torch.cuda.manual_seed(SEED)"
      ],
      "metadata": {
        "id": "ALzPxM3VQtr4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "JWGPA8uGVeSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the directory on your drive to reproduce results. Downloaded data from https://madm.dfki.de/files/sentinel/EuroSATallBands.zip should be within the data folder created in previous steps. "
      ],
      "metadata": {
        "id": "wZXlug-9XpaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eurosat_dir = data_directory.joinpath(\"ds/images/remote_sensing/otherDatasets/sentinel_2/tif\")\n",
        "samples = glob.glob(os.path.join(eurosat_dir, \"*\", \"*.tif\"))\n",
        "len(samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OncGiTgCRC5j",
        "outputId": "33297d43-1ff7-4df9-8219-23f168e51314"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27000"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = {\n",
        "    0: \"AnnualCrop\",\n",
        "    1: \"Forest\",\n",
        "    2: \"HerbaceousVegetation\",\n",
        "    3: \"Highway\",\n",
        "    4: \"Industrial\",\n",
        "    5: \"Pasture\",\n",
        "    6: \"PermanentCrop\",\n",
        "    7: \"Residential\",\n",
        "    8: \"River\",\n",
        "    9: \"SeaLake\"\n",
        "}"
      ],
      "metadata": {
        "id": "VwOhfsv7VeaY"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = {value:key for key,value in classes.items()}"
      ],
      "metadata": {
        "id": "iD6KW5ysbxb3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uaYPzsyb02l",
        "outputId": "031748f7-0a98-41ed-fe43-c6c0bc7d5325"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a user-defined data loader for the EuroSAT data to adjust specifically for a GAN model. This process includes transformations if wanted. "
      ],
      "metadata": {
        "id": "-AZq6GGQZHKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_training_and_testing_sets(file_list):\n",
        "    split = 0.8\n",
        "    random.Random(SEED).shuffle(file_list)\n",
        "    split_index = floor(len(file_list) * split)\n",
        "    training = file_list[:split_index]\n",
        "    testing = file_list[split_index:]\n",
        "    return training, testing"
      ],
      "metadata": {
        "id": "74rZUD6VZHSx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, test_df = get_training_and_testing_sets(samples)"
      ],
      "metadata": {
        "id": "EfNNP3nta7tY"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_train = transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                                                       std = [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "transformer_test = transforms.Compose([\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                                                       std = [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "wqUdGLAqb8Sk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainData(Dataset):\n",
        "\n",
        "    def __init__(self, directories, transform=None):\n",
        "        self.directories = directories\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.directories)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        input = self.directories[idx]\n",
        "        label = input.split('/')[-1].split('_')[0]\n",
        "        label = class_to_idx[label]\n",
        "        with rio.open(input, \"r\") as d:\n",
        "          image = d.read([4,3,2]).astype(int)\n",
        "          image = reshape_as_image(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image.astype(float))\n",
        "            image = image.type(torch.FloatTensor)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "GQSkBmsncG3y"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainData = TrainData(directories = train_df, transform = transformer_train)"
      ],
      "metadata": {
        "id": "RDBFfZ_nmjJt"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestData(Dataset):\n",
        "    def __init__(self, directories, transform=None):\n",
        "        self.directories = directories\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.directories)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        input = self.directories[idx]\n",
        "        label = input.split('/')[-1].split('_')[0]\n",
        "        label = class_to_idx[label]\n",
        "        with rio.open(input, \"r\") as d:\n",
        "          image = d.read([4,3,2]).astype(int)\n",
        "          image = reshape_as_image(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image.astype(float))\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "Cja_tGb6fk-b"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData = TestData(directories = test_df, transform = transformer_test)"
      ],
      "metadata": {
        "id": "vboVWqlbnUPg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testData[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQfh9mRduudS",
        "outputId": "76b6998d-9c0d-4253-8182-5ce3114ef271"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup GAN \n",
        "The GAN architecture is composed of the generative model $G$ and the discriminative model $D$.\n",
        "\n",
        "The discriminator $D$ is a binary classifier trying to determine whether the input sample $X$ is real or fake. Real pictures come from the EuroSAT dataset whereas fake inputs are generated by generator $G$. Thus, $D$ outputs a scalar which is then transformed to a probability measure using the sigmoid function. \n",
        "\n",
        "- 1 - Sample is part of the real dataset\n",
        "- 0 - Sample is a fake generated by $G$"
      ],
      "metadata": {
        "id": "Wwe3tG5Onj9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator\n",
        "Due to the binary classification case of the discriminator we will use the BCE with logits loss because cross entropy not only punishes incorrect but confident predictions but also correct but less confident predictions. Including the logits there is no need to apply the sigmoid activation function in the network. "
      ],
      "metadata": {
        "id": "Qn89tZsbo9rT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the Discriminator network architecture\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    # define the class constructor\n",
        "    def __init__(self):\n",
        "\n",
        "        # call super class constructor\n",
        "        super(Discriminator, self).__init__()\n",
        "        \n",
        "        # specify convoluted layer 1: in 64*64 and three layers\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.activation1 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "        \n",
        "        # specify convoluted layer 2: in 68*68*5, out 32*32*1\n",
        "        self.conv2 = nn.Conv2d(5, 64, kernel_size=(1, 1), stride=(2, 2), padding=(0, 0), bias=False)\n",
        "        self.activation2 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "\n",
        "        # specify fc layer 3: in 32*32, out 64\n",
        "        self.fc3 = nn.Linear(32*32, 64) # the linearity W*x+b\n",
        "        self.activation3 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "        \n",
        "        # specify fc layer 4: in 64, out 1\n",
        "        self.fc4 = nn.Linear(64, 1) # the linearity W*x+b\n",
        "\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "    # define network forward pass\n",
        "    def forward(self, x):\n",
        "\n",
        "        # define fc layer 1 forward pass and add dropout\n",
        "        x = self.activation1(self.conv1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # define fc layer 2 forward pass and add dropout\n",
        "        x = self.activation2(self.conv2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # flatten image\n",
        "        x = x.view(-1, 32*32)\n",
        "\n",
        "        # define fc layer 3 forward pass and add dropout\n",
        "        x = self.activation3(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # define fc layer 4 forward pass\n",
        "        out = self.fc4(x)\n",
        "\n",
        "        # return forward pass result\n",
        "        return out"
      ],
      "metadata": {
        "id": "bCuv9zPgnkDi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator\n",
        "As the generator is not a discriminative model its aim is to generate data. \n",
        "Thus, we draw the latent variable $z \\in \\mathbb{R}^d$ from a random distribution such as a Gaussian or a uniform distribution. \n",
        "Accordingly, $G$ produces the following output: $X' = G(z)$. \n",
        "As we want to fool $D$ to fail in distinguishing fake and real remote sensing data we aspire $D(G(z)) ≈ 1$. Hence, the goal is to maximize cross-entropy loss in case $y=0$ (fake data). "
      ],
      "metadata": {
        "id": "DnIaoVHAp6FB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# implement the Generator network architecture\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    # define the class constructor\n",
        "    def __init__(self):\n",
        "\n",
        "        # call super class constructor\n",
        "        super(Generator, self).__init__()\n",
        "        \n",
        "        # specify fc layer 1: in 100 (from latent space z), out 128\n",
        "        self.fc1 = nn.Linear(100, 128) # the linearity W*x+b\n",
        "        self.activation1 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "\n",
        "        # specify fc layer 2: in 32, out 64\n",
        "        self.fc2 = nn.Linear(128, 256) # the linearity W*x+b\n",
        "        self.activation2 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "\n",
        "        # specify fc layer 3: in 64, out 128\n",
        "        self.fc3 = nn.Linear(256, 512) # the linearity W*x+b\n",
        "        self.activation3 = nn.LeakyReLU(0.2, inplace=True) # the non-linearity\n",
        "        \n",
        "        # specify fc layer 4: in 128, out 28*28\n",
        "        self.fc4 = nn.Linear(512, 64*64) # the linearity W*x+b\n",
        "       \n",
        "        # dropout layer \n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    # define network forward pass\n",
        "    def forward(self, x):\n",
        "\n",
        "        # define fc layer 1 forward pass and add dropout\n",
        "        x = self.activation1(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # define fc layer 2 forward pass and add dropout\n",
        "        x = self.activation2(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # define fc layer 3 forward pass and add dropout\n",
        "        x = self.activation3(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # define fc layer 4 with tanh applied\n",
        "        out = self.fc4(x).tanh()\n",
        "\n",
        "        # return forward pass result\n",
        "        return out"
      ],
      "metadata": {
        "id": "EvRz2iGBxo2c"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MinMax-Game\n",
        "We thus define the following value function $V$ by combining both the targets of $G$ and $D$:\n",
        "\n",
        "$$min_{G}max_{D} V(D, G) = \\mathbb{E}_{x∼Data} [logD(x)] + \\mathbb{E}_{z∼Noise} [log(1-D(G(z)))]$$\n"
      ],
      "metadata": {
        "id": "F1lzmwnQr1fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate both D and G\n",
        "D = Discriminator()\n",
        "G = Generator()"
      ],
      "metadata": {
        "id": "-KjKDsTtubND"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# push to device (GPU)\n",
        "D = D.to(device)\n",
        "G = G.to(device)"
      ],
      "metadata": {
        "id": "WeAlT9jvynV5"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether model is loaded to GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoEfDBGeyq3t",
        "outputId": "905e3cb4-4038-412a-e058-aa9551e0fe5d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 11 16:07:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    26W /  70W |    632MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('[LOG] Discriminator architecture:\\n\\n{}\\n'.format(D))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyPEK57tyxIs",
        "outputId": "15ca225f-ffd3-4c38-baf5-11b08cce5074"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] Discriminator architecture:\n",
            "\n",
            "Discriminator(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (activation1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (conv2): Conv2d(5, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (activation2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=64, bias=True)\n",
            "  (activation3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (fc4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('[LOG] Generator architecture:\\n\\n{}\\n'.format(G))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMI4zxIdy5nQ",
        "outputId": "e3fa7bb7-dc57-4d82-d0f4-240e967e16bd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] Generator architecture:\n",
            "\n",
            "Generator(\n",
            "  (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
            "  (activation1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (fc2): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (activation2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (fc3): Linear(in_features=256, out_features=512, bias=True)\n",
            "  (activation3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (fc4): Linear(in_features=512, out_features=4096, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the loss for the discriminator and push to device\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "m144p1oSy78r"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For further training tips of GANs look at: [GAN hacks](https://https://github.com/soumith/ganhacks)"
      ],
      "metadata": {
        "id": "C-NeMpNnzhG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set learning rate\n",
        "lr = 0.002\n",
        "\n",
        "# create optimizers for the discriminator and generator\n",
        "d_optimizer = optim.SGD(D.parameters(), 0.02) \n",
        "g_optimizer = optim.Adam(G.parameters(), 0.002) "
      ],
      "metadata": {
        "id": "QZ6EBv1AzJ4A"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "s_QkxUiCzxXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify the training parameters\n",
        "num_epochs = 20 # number of training epochs\n",
        "mini_batch_size=64 # size of the mini-batches"
      ],
      "metadata": {
        "id": "vYQSBA9vzu7Q"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(trainData, \n",
        "                                           batch_size=mini_batch_size,\n",
        "                                           shuffle=True\n",
        "                                           )"
      ],
      "metadata": {
        "id": "p1ZEjpHsz5X4"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ819rH60AP5",
        "outputId": "2dd6c906-1e4c-45d1-b5e4-a285db384a95"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "338"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# establish convention for real and fake labels during training\n",
        "real_label = 1\n",
        "fake_label = 0"
      ],
      "metadata": {
        "id": "LiP-VNUc0FEM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define size of latent vector\n",
        "z_size = 100\n",
        "\n",
        "# define sample size\n",
        "sample_size = 4\n",
        "\n",
        "# uniformly distribute data of size z_size over an interval of -1; 1\n",
        "fixed_noise = np.random.normal(0, 1, size=(sample_size, z_size))\n",
        "\n",
        "# create numpy array into tensor, and convert data to float\n",
        "fixed_noise = torch.from_numpy(fixed_noise).float()\n",
        "\n",
        "# push the fixed vector to the device that's enabled\n",
        "fixed_noise = fixed_noise.to(device)"
      ],
      "metadata": {
        "id": "pgV8S6u70MDU"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize list of the generated (fake) images\n",
        "fake_images = []\n",
        "\n",
        "# initialize collection of batch losses\n",
        "D_batch_losses = []\n",
        "G_batch_losses = []\n",
        "\n",
        "# initialize collection of epoch losses\n",
        "D_epoch_losses = []\n",
        "G_epoch_losses = []\n",
        "\n",
        "# set networks to training mode\n",
        "D.train()\n",
        "G.train()\n",
        "\n",
        "# define time right before training\n",
        "start = time.datetime.now()\n",
        "\n",
        "# train the GANs\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    # iterate over mini batches\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "        # define real images and push to computation device\n",
        "        real_images = data[0].to(device)\n",
        "\n",
        "        # define batch size as size of the images to make sure the loader is emptied completely\n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # --------------------------------------------------------------------------\n",
        "        # (1) Update Discriminator network\n",
        "\n",
        "        #### train with real images\n",
        "\n",
        "        # create tensor of same size as mini-batch and filled with 1's (real_label)\n",
        "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
        "\n",
        "        # rescaling input images from [0,1) to [-1, 1), which is needed for network\n",
        "        real_images = real_images*2 - 1\n",
        "\n",
        "        # run forward pass through Discriminator\n",
        "        output = D(real_images) #.view(-1)\n",
        "\n",
        "        # reset graph gradients\n",
        "        D.zero_grad()\n",
        "\n",
        "        # determine loss on Discriminator\n",
        "        errD_real = criterion(output, label)\n",
        "\n",
        "        # run backward pass\n",
        "        errD_real.backward()\n",
        "    \n",
        "        #### train with fake images\n",
        "\n",
        "        # generate batch of latent vectors\n",
        "        z = np.random.normal(0, 1, size=(batch_size, z_size))\n",
        "        z = torch.from_numpy(z).float()\n",
        "        z = z.to(device)\n",
        "\n",
        "        # generate fake image batch with Generator\n",
        "        fake = G(z)\n",
        "\n",
        "        # fills label tensor with 0's (fake_label)\n",
        "        label.fill_(fake_label)\n",
        "\n",
        "        # classify all fake batch with Discriminator\n",
        "        output = D(fake.detach()).view(-1)\n",
        "\n",
        "        # get discriminator loss on the fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "\n",
        "        # run backward pass\n",
        "        errD_fake.backward()\n",
        "\n",
        "        # compute error of Discriminator as sum of loss over the fake and the real batches\n",
        "        errD = errD_fake + errD_real\n",
        "\n",
        "        # update Discriminator parameters\n",
        "        d_optimizer.step()\n",
        "\n",
        "\n",
        "        # --------------------------------------------------------------------------\n",
        "        # (2) Update Generator network\n",
        "\n",
        "        # reset graph gradients\n",
        "        G.zero_grad()\n",
        "\n",
        "        # fake labels are real for generator\n",
        "        label.fill_(real_label)\n",
        "\n",
        "        # since we just updated D, perform another forward pass of fake batch through the Discriminator\n",
        "        output = D(fake).view(-1)\n",
        "\n",
        "        # get Generator loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "\n",
        "        # run backward pass\n",
        "        errG.backward()\n",
        "\n",
        "        # update Generator paramaters\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # --------------------------------------------------------------------------\n",
        "\n",
        "        # each 250 iterations (4x per epoch), print losses\n",
        "        if i % 500 == 0:\n",
        "          now = datetime.utcnow().strftime(\"%H:%M:%S\")\n",
        "          print('[LOG {}] Epoch [{}/{}] \\t[{}/{}] \\t d_loss: {} \\t g_loss: {}'.format(\n",
        "              now, epoch+1, num_epochs,i, len(train_loader), errD.item(), errG.item()))\n",
        "          \n",
        "        # save losses for plotting later\n",
        "        D_batch_losses.append(errD.item())\n",
        "        G_batch_losses.append(errG.item())\n",
        "\n",
        "        # set Generator to eval mode for generating samples (equivalent to 'testing' the model)\n",
        "        G.eval() \n",
        "\n",
        "        # make Generator generate samples from the fixed noise ditribution\n",
        "        samples = G(fixed_noise.float())\n",
        "\n",
        "        # if you are using a GPU, copy tensor to host memory (cpu) - needed for later operations\n",
        "        if device == 'cuda':\n",
        "          samples = samples.cpu()\n",
        "\n",
        "        # append generated fixed samples to the fake_images list\n",
        "        fake_images.append(samples)\n",
        "\n",
        "        # set Generator back to train mode\n",
        "        G.train()\n",
        "\n",
        "    # determine mean min-batch loss of epoch\n",
        "    D_epoch_loss = np.mean(D_batch_losses)\n",
        "\n",
        "    D_epoch_losses.append(D_epoch_loss)\n",
        "\n",
        "    # determine mean min-batch loss of epoch\n",
        "    G_epoch_loss = np.mean(G_batch_losses)\n",
        "\n",
        "    G_epoch_losses.append(G_epoch_loss)\n",
        "\n",
        "    # set filename of actual model\n",
        "    d_model_name = 'gan_d_model_epoch_{}.pth'.format(str(epoch+1))\n",
        "\n",
        "    # set filename of actual model\n",
        "    g_model_name = 'gan_g_model_epoch_{}.pth'.format(str(epoch+1))\n",
        "\n",
        "    # save current model to GDrive models directory\n",
        "    torch.save(D.state_dict(), os.path.join(models_directory, d_model_name))\n",
        "\n",
        "    # save current model to GDrive models directory\n",
        "    torch.save(G.state_dict(), os.path.join(models_directory, g_model_name))\n",
        "\n",
        "# save generated samples with pickle\n",
        "with open('fake_images.pkl', 'wb') as f:\n",
        "  pkl.dump(fake_images, f)\n",
        "\n",
        "# print total training time\n",
        "print('\\nTotal training time:', time.datetime.now() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dHdMRXyK1MeL",
        "outputId": "73008bfd-82b2-4e60-f51c-b12d4ab597bc"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-752b0300d413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# run forward pass through Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.view(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# reset graph gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-2e79ce0d9f4f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# define fc layer 2 forward pass and add dropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 5, 1, 1], expected input[64, 64, 64, 64] to have 5 channels, but got 64 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0-aFcoUv2HM6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}