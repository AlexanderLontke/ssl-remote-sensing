{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Classification Downstream Task "
   ],
   "metadata": {
    "id": "jg21-fZ0lbYb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install ssl_remote_sensing@git+https://github.com/AlexanderLontke/ssl-remote-sensing.git@feature/pipeline"
   ],
   "metadata": {
    "id": "hhzpyIoDlFIO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Log in to your W&B account\n",
    "import wandb\n",
    "wandb.login()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Xw_sd7yXk44b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision.datasets import EuroSAT\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from ssl_remote_sensing.downstream_tasks.classification.model import DownstreamClassificationNet\n",
    "from ssl_remote_sensing.downstream_tasks.classification.util import get_subset_samplers_for_train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Loading ##"
   ],
   "metadata": {
    "id": "W7eACD6JllJ3",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class RunConfig:\n",
    "    def __init__(self):\n",
    "        self.num_epochs = 10  # number of training epochs\n",
    "        self.seed = 1234  # randomness seed\n",
    "        self.save = \"./saved_models/\"  # save checkpoint\n",
    "        self.batch_size = 64\n",
    "        self.learning_rate = 1e-3\n",
    "        self.embedding_size = 128  # papers value is 128\n",
    "        self.test_split_ratio = 0.2\n",
    "config = RunConfig()\n",
    "wandb.init(\n",
    "    project=\"ssl-remote-sensing-classification\",\n",
    "    config=config.__dict__,\n",
    ")"
   ],
   "metadata": {
    "id": "5BS5vVgbsTuv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup data loading\n",
    "# TODO add normalization\n",
    "eurosat_ds = EuroSAT(root=\"./\", download=True, transform=T.ToTensor())\n",
    "dataset_size = len(eurosat_ds)\n",
    "\n",
    "train_sampler, test_sampler = get_subset_samplers_for_train_test_split(\n",
    "    dataset_size, test_split_ratio=config.test_split_ratio\n",
    ")\n",
    "train_dl = DataLoader(\n",
    "    dataset=eurosat_ds,\n",
    "    batch_size=128,\n",
    "    sampler=train_sampler,\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    dataset=eurosat_ds,\n",
    "    batch_size=128,\n",
    "    sampler=test_sampler,\n",
    ")"
   ],
   "metadata": {
    "id": "QXrLUKc_o8mc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training ##\n"
   ],
   "metadata": {
    "id": "DXO-e_p0lorb",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# First of all, let's verify if a GPU is available on our compute machine. If not, the cpu will be used instead.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device used: {}\".format(device))\n",
    "\n",
    "model = DownstreamClassificationNet(input_dim=72 * 13 * 13).to(device)\n",
    "\n",
    "# define the optimization criterion / loss function\n",
    "loss_criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gtw7Jz_gzt9_",
    "outputId": "481a801f-cd09-4541-bbf4-743a7bbcbea9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device used: cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(config.num_epochs)):\n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "\n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(train_dl):\n",
    "\n",
    "        # push mini-batch data to computation device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        out = model(images)\n",
    "        loss = loss_criterion(out, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "        wandb.log({\n",
    "            \"step/training_loss\": loss.data.item(),\n",
    "        })\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "\n",
    "    # Specify you are in evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_mini_batch_losses = []\n",
    "        for (images, labels) in test_dl:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            validation_epoch_loss = loss_criterion(outputs, labels)\n",
    "            # collect mini-batch reconstruction loss\n",
    "            validation_mini_batch_losses.append(validation_epoch_loss.data.item())\n",
    "        validation_epoch_loss = np.mean(validation_mini_batch_losses)\n",
    "\n",
    "    wandb.log({\n",
    "        \"epoch/training_loss\": train_epoch_loss,\n",
    "        \"epoch/validation_loss\": validation_epoch_loss,\n",
    "    })\n",
    "\n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print(\n",
    "        f\"[LOG {now}] epoch: {epoch+1} train-loss: {train_epoch_loss} validation-loss: {validation_epoch_loss}\"\n",
    "    )"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mHL2cwPnx0uo",
    "outputId": "6024d730-a39b-4415-d7e0-3506074e760e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:15<00:00, 11.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:33:44] epoch: 1 train-loss: 1.480928829435766 validation-loss: 1.2402197122573853\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:12<00:00, 13.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:33:59] epoch: 2 train-loss: 1.0071332916705567 validation-loss: 0.8630091547966003\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:13<00:00, 12.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:34:14] epoch: 3 train-loss: 0.7849056743658506 validation-loss: 0.7523846626281738\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:12<00:00, 13.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:34:30] epoch: 4 train-loss: 0.6741639231083661 validation-loss: 0.7110217213630676\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:13<00:00, 12.81it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:34:45] epoch: 5 train-loss: 0.6494043100867751 validation-loss: 0.5024420619010925\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:12<00:00, 13.26it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:35:00] epoch: 6 train-loss: 0.5615866159546304 validation-loss: 0.5328946113586426\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:12<00:00, 13.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:35:16] epoch: 7 train-loss: 0.5410281814767058 validation-loss: 0.7607574462890625\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:12<00:00, 13.21it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:35:31] epoch: 8 train-loss: 0.479756369745943 validation-loss: 0.3574117422103882\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:16<00:00, 10.32it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:35:51] epoch: 9 train-loss: 0.44355890243011115 validation-loss: 0.48850345611572266\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 169/169 [00:13<00:00, 12.76it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[LOG 20221027-13:36:07] epoch: 10 train-loss: 0.40241120023840277 validation-loss: 0.3943125307559967\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Evaluation ##"
   ],
   "metadata": {
    "id": "PxJWfmsPlr1a",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "# iterate over test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for (images, labels) in tqdm(test_dl, desc=\"Predict labels\"):\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs = model(images)  # Feed Network\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        y_pred.extend(predicted.cpu().numpy())  # Save Prediction\n",
    "        y_true.extend(labels.numpy())  # Save Truth"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4XixeAvfn8R",
    "outputId": "6f2647c0-ecfa-4f6c-9494-6c7cac3725e8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Predict labels: 100%|██████████| 43/43 [00:02<00:00, 17.45it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8DY4-_sqCyQ",
    "outputId": "7b73ff58-c100-40d3-c56f-2426e206a1b4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.77      0.84       595\n",
      "           1       0.84      0.92      0.88       606\n",
      "           2       0.80      0.72      0.76       602\n",
      "           3       0.69      0.56      0.62       515\n",
      "           4       0.83      0.97      0.89       493\n",
      "           5       0.75      0.75      0.75       423\n",
      "           6       0.65      0.73      0.69       473\n",
      "           7       0.91      0.96      0.93       597\n",
      "           8       0.61      0.79      0.69       490\n",
      "           9       0.98      0.78      0.87       606\n",
      "\n",
      "    accuracy                           0.80      5400\n",
      "   macro avg       0.80      0.79      0.79      5400\n",
      "weighted avg       0.81      0.80      0.80      5400\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "2TmqG4RiqT0U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}