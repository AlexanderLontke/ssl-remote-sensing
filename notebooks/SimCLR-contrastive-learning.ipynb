{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SimCLR implementation #"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implementation following: https://theaisummer.com/simclr/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision.datasets import STL10, EuroSAT\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.multiprocessing import cpu_count\n",
    "from pytorch_lightning.callbacks import GradientAccumulationScheduler, ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "\n",
    "from ssl_remote_sensing.data.eurosat_dataset import means, stds\n",
    "from ssl_remote_sensing.pretext_tasks.simclr.utils import reproducibility\n",
    "from ssl_remote_sensing.pretext_tasks.simclr.training import SimCLRTraining\n",
    "from ssl_remote_sensing.pretext_tasks.simclr.augmentation import Augment"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_stl_dataloader(batch_size, transform=None, split=\"unlabeled\"):\n",
    "    stl10 = STL10(\"/Users/alexanderlontke/datasets/\", split=split, transform=transform, download=True)\n",
    "    return DataLoader(dataset=stl10, batch_size=batch_size, num_workers=cpu_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Putting it all together ##"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available_gpus: 0\n",
      "DIM MLP input: 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderlontke/.conda/envs/ssl-remote-sensing/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/alexanderlontke/.conda/envs/ssl-remote-sensing/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:616: UserWarning: Checkpoint directory /Users/alexanderlontke/Documents/Uni/St. Gallen/HS_22_23/deep_learning/ssl-remote-sensing/notebooks/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name  | Type          | Params\n",
      "----------------------------------------\n",
      "0 | model | AddProjection | 11.5 M\n",
      "1 | loss  | InfoNceLoss   | 0     \n",
      "----------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "46.024    Total estimated model params size (MB)\n",
      "/Users/alexanderlontke/.conda/envs/ssl-remote-sensing/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer Adam, Learning Rate 0.001, Effective batch size 64\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46d72a726262411dbf80ea37b8097097"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask torch.Size([128, 128])\n",
      "exp torch.Size([128, 128])\n",
      "mask torch.Size([128, 128])\n",
      "exp torch.Size([128, 128])\n",
      "mask torch.Size([128, 128])\n",
      "exp torch.Size([128, 128])\n",
      "mask torch.Size([16, 16])\n",
      "exp torch.Size([16, 16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# Machine setup\n",
    "available_gpus = torch.cuda.device_count()\n",
    "save_model_path = os.path.join(os.getcwd(), \"saved_models/\")\n",
    "print(\"available_gpus:\", available_gpus)\n",
    "\n",
    "# Run setup\n",
    "filename = \"SimCLR_ResNet18_adam\"\n",
    "save_name = filename + '.ckpt'\n",
    "resume_from_checkpoint = False\n",
    "\n",
    "\n",
    "# Model Setup\n",
    "class Hparams:\n",
    "    def __init__(self):\n",
    "        self.epochs = 1  # number of training epochs\n",
    "        self.seed = 1234  # randomness seed\n",
    "        self.cuda = False  # use nvidia gpu\n",
    "        self.img_size = 64  #image shape\n",
    "        self.save = \"./saved_models/\"  # save checkpoint\n",
    "        self.gradient_accumulation_steps = 1  # gradient accumulation steps\n",
    "        self.batch_size = 64\n",
    "        self.lr = 1e-3\n",
    "        self.embedding_size = 128  # papers value is 128\n",
    "        self.temperature = 0.5  # 0.1 or 0.5\n",
    "        self.weight_decay = 1e-6\n",
    "\n",
    "\n",
    "train_config = Hparams()\n",
    "reproducibility(train_config)\n",
    "\n",
    "model = SimCLRTraining(\n",
    "    config=train_config,\n",
    "    model=models.resnet18(weights=None),\n",
    "    feat_dim=512,\n",
    "    norm_means=means,\n",
    "    norm_stds=stds\n",
    ")\n",
    "\n",
    "transform = Augment(\n",
    "    train_config.img_size, norm_means=means, norm_stds=stds\n",
    ")\n",
    "\n",
    "dataset = EuroSAT(\n",
    "    \"/Users/alexanderlontke/datasets/\",\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "data_loader = DataLoader(\n",
    "    dataset=torch.utils.data.Subset(dataset,range(200)),\n",
    "    batch_size=train_config.batch_size,\n",
    "    num_workers=cpu_count()\n",
    ")\n",
    "\n",
    "# Needed to get simulate a large batch size\n",
    "accumulator = GradientAccumulationScheduler(scheduling={0: 1})\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filename=filename,\n",
    "    dirpath=save_model_path,\n",
    "    every_n_epochs=2,\n",
    "    save_last=True,\n",
    "    save_top_k=2,\n",
    "    monitor='Contrastive loss_epoch',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "if resume_from_checkpoint:\n",
    "    trainer = Trainer(\n",
    "        callbacks=[accumulator, checkpoint_callback],\n",
    "        gpus=available_gpus,\n",
    "        max_epochs=train_config.epochs,\n",
    "        resume_from_checkpoint=train_config.checkpoint_path\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        callbacks=[accumulator, checkpoint_callback],\n",
    "        gpus=available_gpus,\n",
    "        max_epochs=train_config.epochs\n",
    "    )\n",
    "\n",
    "trainer.fit(model, data_loader)\n",
    "trainer.save_checkpoint(save_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3,64,64))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-4.9118, grad_fn=<DivBackward0>)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ssl_remote_sensing.pretext_tasks.simclr.loss import InfoNceLoss\n",
    "(x1, x2), label = next(iter(data_loader))\n",
    "z1 = model(x1)\n",
    "z2 = model(x2)\n",
    "InfoNceLoss(train_config.batch_size).forward(z1, z2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ssl-remote-sensing",
   "language": "python",
   "display_name": "ssl-remote-sensing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}